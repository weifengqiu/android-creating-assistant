（1） 采样率（samplerate）
      采样就是把模拟信号数字化的过程，不仅仅是音频需要采样，所有的模拟信号都需要通过采样转换为可以用0101来表示的数字信号。
      根据奈奎斯特理论，采样频率只要不低于音频信号最高频率的两倍，就可以无损失地还原原始的声音。
      通常人耳能听到频率范围大约在20Hz～20kHz之间的声音，为了保证声音不失真，采样频率应在40kHz以上。
      常用的音频采样频率有：8kHz、11.025kHz、22.05kHz、16kHz、37.8kHz、44.1kHz、48kHz、96kHz、192kHz等。
（2） 量化精度（位宽）
      每一个采样点，都需要用一个数值来表示大小，这个数值的数据类型大小可以是：4bit、8bit、16bit、32bit等等，位数越多，表示得就越精细，
      声音质量自然就越好，当然，数据量也会成倍增大。常见的位宽是：8bit 或者 16bit
（3） 声道数（channels）
      由于音频的采集和播放是可以叠加的，因此，可以同时从多个音频源采集声音，并分别输出到不同的扬声器，
      故声道数一般表示声音录制时的音源数量或回放时相应的扬声器数量。
      单声道（Mono）和双声道（Stereo）比较常见，顾名思义，前者的声道数为1，后者为2      
（4） 音频帧（frame）
      这个概念在应用开发中非常重要，网上很多文章都没有专门介绍这个概念。
      音频跟视频很不一样，视频每一帧就是一张图像，而从上面的正玄波可以看出，音频数据是流式的，本身没有明确的一帧帧的概念，
      在实际的应用中，为了音频算法处理/传输的方便，一般约定俗成取2.5ms~60ms为单位的数据量为一帧音频。
      这个时间被称之为“采样时间”，其长度没有特别的标准，它是根据编解码器和具体应用的需求来决定的，我们可以计算一下一帧音频帧的大小：
      假设某通道的音频信号是采样率为8kHz，位宽为16bit，20ms一帧，双通道，则一帧音频数据的大小为：
      int size = 8000 x 16bit x 0.02s  x 2 = 5120 bit = 640 byte      
 
